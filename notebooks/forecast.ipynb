{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ewalt/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, shutil\n",
    "import xarray as xr\n",
    "import torch\n",
    "import dask\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import logging\n",
    "import dataclasses\n",
    "\n",
    "from aurora import Batch\n",
    "\n",
    "from aurora_benchmark.utils import verbose_print, xr_to_netcdf\n",
    "\n",
    "from aurora_benchmark.parallel import AuroraBatchDataParallel, rollout, ParallelAurora, ParallelAuroraSmall\n",
    "from aurora_benchmark.data import (\n",
    "    XRAuroraDataset, \n",
    "    XRAuroraBatchedDataset,\n",
    "    aurora_batch_collate_fn, \n",
    "    aurora_batch_to_xr, \n",
    "    unpack_aurora_batch\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Suppress logs from Google libraries\n",
    "logging.getLogger('google').setLevel(logging.ERROR)\n",
    "logging.getLogger('google.auth').setLevel(logging.ERROR)\n",
    "logging.getLogger('google.cloud').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/home/ewalt/.local/lib/python3.11/site-packages/xarray/core/dataset.py:273: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 50. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(FrozenMappingWarningOnValuesAccess({'latitude': 721, 'longitude': 1440, 'time': 1460}),\n",
       " FrozenMappingWarningOnValuesAccess({'latitude': 721, 'level': 13, 'longitude': 1440, 'time': 1460}),\n",
       " FrozenMappingWarningOnValuesAccess({'latitude': 721, 'longitude': 1440}))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "era5_surface_paths = [\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/10v_2021-2022-6h-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/2t_2021-2022-6h-1440x721.nc\",\n",
    "#  - data/era5_wb2/2021-2022-6h-1440x721/tp_2021-2022-6h-1440x721.nc # original only\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/10u_2021-2022-6h-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/msl_2021-2022-6h-1440x721.nc\",\n",
    "#  - data/era5_wb2/2021-2022-6h-1440x721/sst_2021-2022-6h-1440x721.nc # original only\n",
    "]\n",
    "era5_atmospheric_paths = [\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/q_2021-2022-6h-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/t_2021-2022-6h-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/u_2021-2022-6h-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/v_2021-2022-6h-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/z_2021-2022-6h-1440x721.nc\",\n",
    "]\n",
    "era5_static_paths = [\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/lsm_static-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/z_static-1440x721.nc\",\n",
    "\"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/slt_static-1440x721.nc\",\n",
    "]\n",
    "\n",
    "forecast_dir = \"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2_forecasts/2021-2022-6h-1d-6w-1440x721_original_variables/\"\n",
    "eval_dir = \"../figures/era5_wb2_eval/2021-2022-6h-1d-6w-1440x721_original_variables\"\n",
    "\n",
    "# Load the data into a single dataset with the same coords but multiple variables\n",
    "surface_ds = xr.merge([\n",
    "    xr.open_dataset(p, engine=\"netcdf4\", chunks={\"time\": 50, \"latitude\": 721, \"longitude\": 1440})\n",
    "    for p in era5_surface_paths\n",
    "])\n",
    "\n",
    "atmospheric_ds = xr.merge([\n",
    "    xr.open_dataset(p, engine=\"netcdf4\", chunks={\"time\": 50, \"latitude\": 721, \"longitude\": 1440, \"level\": 1})\n",
    "    for p in era5_atmospheric_paths\n",
    "])\n",
    "\n",
    "static_ds = xr.merge([\n",
    "    xr.open_dataset(p, engine=\"netcdf4\", chunks={\"latitude\": 721, \"longitude\": 1440})\n",
    "    for p in era5_static_paths\n",
    "])\n",
    "\n",
    "surface_ds.dims, atmospheric_ds.dims, static_ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# era5_surface_paths = [\n",
    "#     \"../toy_data/era5-1d-360x180/msl-2021-2022-1d-360x180.nc\",\n",
    "#     \"../toy_data/era5-1d-360x180/t2m-2021-2022-1d-360x180.nc\",\n",
    "#     \"../toy_data/era5-1d-360x180/u10-2021-2022-1d-360x180.nc\",\n",
    "#     \"../toy_data/era5-1d-360x180/v10-2021-2022-1d-360x180.nc\",\n",
    "# ]\n",
    "# era5_atmospheric_paths = [ \n",
    "#     \"../toy_data/era5-1d-360x180/t-2021-2022-1d-360x180.nc\",\n",
    "#     \"../toy_data/era5-1d-360x180/q-2021-2022-1d-360x180.nc\",\n",
    "#     \"../toy_data/era5-1d-360x180/u-2021-2022-1d-360x180.nc\",\n",
    "#     \"../toy_data/era5-1d-360x180/v-2021-2022-1d-360x180.nc\",\n",
    "#     \"../toy_data/era5-1d-360x180/z-2021-2022-1d-360x180.nc\",\n",
    "# ]\n",
    "# era5_static_paths = [\n",
    "#     \"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/lsm_static-1440x721.nc\",\n",
    "#     \"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/z_static-1440x721.nc\",\n",
    "#     \"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2/2021-2022-6h-1440x721/slt_static-1440x721.nc\",\n",
    "# ]\n",
    "\n",
    "# # Load the data into a single dataset with the same coords but multiple variables\n",
    "# surface_dss = [\n",
    "#     xr.open_dataset(path, engine=\"netcdf4\").drop_vars(\"time_bnds\")\n",
    "#     #xr.open_dataset(path, engine=\"h5netcdf\").rename({\"msl\": svar}).drop_vars(\"time_bnds\")\n",
    "#     #xr.open_zarr(path, chunks={\"time\": 50, \"latitude\": 180, \"longitude\": 360}).rename({\"msl\": svar})#.drop_vars(\"time_bnds\")\n",
    "#     for path in era5_surface_paths\n",
    "# ]\n",
    "# surface_ds = xr.merge(surface_dss).rename({\"t2m\": \"2t\", \"u10\": \"10u\", \"v10\": \"10v\", \"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "# atmospheric_dss = [\n",
    "#     xr.open_dataset(path, engine=\"netcdf4\").drop_vars(\"time_bnds\")\n",
    "#     #xr.open_dataset(path, engine=\"h5netcdf\").rename({\"msl\": svar}).expand_dims({\"level\": [1000, 700, 250]}).drop_vars(\"time_bnds\")\n",
    "#     #xr.open_zarr(path, chunks={\"time\": 50, \"latitude\": 180, \"longitude\": 360, \"level\": 1}).rename({\"msl\": svar}).expand_dims({\"level\": [1000, 700, 250]})#.drop_vars(\"time_bnds\")\n",
    "#     for path in era5_atmospheric_paths\n",
    "# ]\n",
    "# atmospheric_ds = xr.merge(atmospheric_dss).rename({\"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "# static_dss = [\n",
    "#      xr.open_dataset(path, engine=\"netcdf4\").coarsen(longitude=1440//360, latitude=721//180, boundary=\"trim\").mean()\n",
    "#     # xr.open_dataset(path, engine=\"h5netcdf\").rename({\"msl\": svar}).isel(time=0).drop_vars(\"time_bnds\")\n",
    "#     #xr.open_zarr(path, chunks={\"latitude\": 180, \"longitude\": 360}).rename({\"msl\": svar}).isel(time=0)#.drop_vars(\"time_bnds\")\n",
    "#     for path in era5_static_paths\n",
    "# ]\n",
    "# static_ds = xr.merge(static_dss)\n",
    "\n",
    "\n",
    "# print(\"TESTING PARALLEL ON TOY DATA!!!!\")\n",
    "# surface_ds.dims, atmospheric_ds.dims, static_ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 10:06:13,460 - aurora_benchmark.utils - INFO - Using dask scheduler: threads\n",
      "2024-10-17 10:06:13,461 - aurora_benchmark.utils - INFO - Creating XRAuroraBatchedDataset ...\n",
      "2024-10-17 10:06:13,467 - aurora_benchmark.utils - INFO - interest_vars: ['t', 'q', 'z', 'u', 'v', '2t', 'msl', '10u', '10v'], interest_levels: [1000, 500, 250]\n",
      "2024-10-17 10:06:13,468 - aurora_benchmark.utils - INFO - Dataset length: 12\n",
      "2024-10-17 10:06:13,468 - aurora_benchmark.utils - INFO - Dataloader length: 12 (type: <class 'aurora_benchmark.data.XRAuroraBatchedDataset'>, batch_size: 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2_forecasts/2021-2022-6h-1w-6w-1440x721_notebook/\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "num_workers = 2\n",
    "eval_start =\"1w\"\n",
    "era5_base_frequency = \"6h\"\n",
    "forecast_horizon = \"6w\"\n",
    "use_dataloader = False\n",
    "eval_aggregation = \"1w\"\n",
    "init_frequency = \"1w\"\n",
    "verbose = True\n",
    "drop_timestamps = False\n",
    "persist = False\n",
    "rechunk = False\n",
    "output_dir = \"/projects/prjs0981/ewalt/aurora_benchmark/data/era5_wb2_forecasts/2021-2022-6h-1w-6w-1440x721_notebook/\"\n",
    "\n",
    "surf_vars = [\"2t\", \"msl\", \"10u\", \"10v\"]\n",
    "atmospheric_vars = [\"t\", \"q\", \"z\", \"u\", \"v\"]\n",
    "static_vars = [\"z\", \"lsm\", \"slt\"]\n",
    "\n",
    "interest_variables = atmospheric_vars + surf_vars\n",
    "interest_levels = [1000, 500, 250]\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "warmup_steps = int(pd.Timedelta(eval_start) / pd.Timedelta(era5_base_frequency)) if eval_start is not None else 0\n",
    "forecast_steps = int(pd.Timedelta(forecast_horizon) / pd.Timedelta(era5_base_frequency))\n",
    "\n",
    "assert (forecast_steps-warmup_steps) * pd.Timedelta(era5_base_frequency) >= pd.Timedelta(eval_aggregation), \"Evaluation steps must be at least as long as eval_aggregation\" \n",
    "\n",
    "if use_dataloader:\n",
    "    dask.config.set(scheduler='synchronous')\n",
    "else:\n",
    "    dask.config.set(scheduler='threads')\n",
    "verbose_print(verbose, f\"Using dask scheduler: {dask.config.get('scheduler')}\")\n",
    "\n",
    "\n",
    "if use_dataloader:\n",
    "    verbose_print(verbose, f\"Creating XRAuroraDataset and DataLoader...\")\n",
    "    dataset = XRAuroraDataset(\n",
    "        surface_ds=surface_ds,\n",
    "        atmospheric_ds=atmospheric_ds,\n",
    "        static_ds=static_ds,\n",
    "        init_frequency=init_frequency,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        num_time_samples=2, # Aurora has fixed history length of 2...\n",
    "        drop_timestamps=drop_timestamps,\n",
    "        persist=persist,\n",
    "        rechunk=rechunk,\n",
    "        atmospheric_variables=atmospheric_vars,\n",
    "        surface_variables=surf_vars,\n",
    "        static_variables=static_vars,\n",
    "    )\n",
    "    verbose_print(verbose, f\"Loaded dataset of length {len(dataset)} (drop_timestamps={drop_timestamps}, persist={persist}, rechunk={rechunk})\")\n",
    "    \n",
    "    num_workers = 2 #int(os.getenv('SLURM_CPUS_PER_TASK', 1))+2 if os.getenv('SLURM_CPUS_PER_TASK') is not None else os.cpu_count()+2\n",
    "    verbose_print(verbose, f\"Creating DataLoader with {num_workers} workers ...\")\n",
    "    eval_loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        collate_fn=aurora_batch_collate_fn,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    batch_iterator = eval_loader\n",
    "else:\n",
    "    # This is done to avoid the issue with torch DataLoader and dask\n",
    "    # when using netcdf files (i.e. netcdf backend is not thread safe)\n",
    "    verbose_print(verbose, f\"Creating XRAuroraBatchedDataset ...\")\n",
    "    dataset = XRAuroraBatchedDataset(\n",
    "        batch_size=batch_size,\n",
    "        surface_ds=surface_ds,\n",
    "        atmospheric_ds=atmospheric_ds,\n",
    "        static_ds=static_ds,\n",
    "        init_frequency=init_frequency,\n",
    "        forecast_horizon=forecast_horizon,\n",
    "        num_time_samples=2, # Aurora has fixed history length of 2...\n",
    "        drop_timestamps=drop_timestamps,\n",
    "        persist=persist,\n",
    "        rechunk=rechunk,\n",
    "        atmospheric_variables=atmospheric_vars,\n",
    "        surface_variables=surf_vars,\n",
    "        static_variables=static_vars,\n",
    "    )\n",
    "    batch_iterator = dataset\n",
    "\n",
    "verbose_print(verbose, f\"interest_vars: {interest_variables}, interest_levels: {interest_levels}\")\n",
    "verbose_print(verbose, f\"Dataset length: {dataset.flat_length() if hasattr(dataset, 'flat_length') else len(dataset)}\")\n",
    "verbose_print(verbose, f\"Dataloader length: {len(batch_iterator)} (type: {type(batch_iterator)}, batch_size: {batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 10:06:21,107 - aurora_benchmark.utils - INFO - loading model ...\n",
      "2024-10-17 10:06:47,303 - aurora_benchmark.utils - INFO - Using 4 GPUs\n",
      "2024-10-17 10:06:47,849 - aurora_benchmark.utils - INFO - Evaluating on cuda\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "verbose_print(verbose, \"loading model ...\")\n",
    "aurora_model = \"aurora-0.25-pretrained.ckpt\"\n",
    "model = ParallelAurora(use_lora=False)\n",
    "model.load_checkpoint(\"microsoft/aurora\", aurora_model)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    verbose_print(verbose, f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = AuroraBatchDataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "verbose_print(verbose, f\"Evaluating on {device}\")\n",
    "# evaluation loop\n",
    "with torch.inference_mode() and torch.no_grad():\n",
    "    for i, batch in enumerate(batch_iterator):\n",
    "        verbose_print(verbose,f\"Rollout prediction on batch {i} ...\")\n",
    "        if batch is None: break\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        # rollout until for forecast_steps\n",
    "        trajectories = [[] for _ in range(batch_size)]\n",
    "        for s, batch_pred in enumerate(rollout(model, batch, steps=forecast_steps)):\n",
    "            if s < warmup_steps:\n",
    "                verbose_print(verbose,f\" * Rollout step {s+1}: skipping warmup period\")\n",
    "                continue            \n",
    "            # separate batched batches\n",
    "            sub_batch_preds = unpack_aurora_batch(batch_pred.to(\"cpu\"))\n",
    "            verbose_print(verbose,f\" * Rollout step {s+1}: unpacked {len(sub_batch_preds)} sub-batches\")\n",
    "            if i != len(batch_iterator) - 1: # the last batch may not be full\n",
    "                assert len(sub_batch_preds) == batch_size\n",
    "            # accumulate\n",
    "            for b, sub_batch_pred in enumerate(sub_batch_preds):\n",
    "                trajectories[b].append(sub_batch_pred)\n",
    "        \n",
    "        # convert to xr and process\n",
    "        verbose_print(verbose,f\"Processing trajectories ...\")\n",
    "        for init_time, trajectory in zip(batch.metadata.time, trajectories):\n",
    "            verbose_print(verbose,f\" * init_time={init_time}: combining {len(trajectory)} steps\")\n",
    "            assert len(trajectory) == forecast_steps-warmup_steps\n",
    "            # collate trajectory batches\n",
    "            trajectory = aurora_batch_collate_fn(trajectory)\n",
    "            # convert to xr.Dataset\n",
    "            trajectory = aurora_batch_to_xr(trajectory, frequency=era5_base_frequency)\n",
    "            \n",
    "            # process individual trajectory elements (i.e. variable types)\n",
    "            for var_type, vars_ds in trajectory.items():\n",
    "                # ensure processing is necessary\n",
    "                if var_type == \"static_ds\":\n",
    "                    verbose_print(verbose,f\" * Skipping static variables\")\n",
    "                    continue # we do not care about static variables for the forecast\n",
    "                if not any([var in vars_ds.data_vars for var in interest_variables]):\n",
    "                    verbose_print(verbose,f\" * Skipping {var_type} variables as no interest variables are present\")\n",
    "                    continue # don't bother processing variables we are not interested in\n",
    "                if var_type == \"atmospheric_ds\" and (interest_levels is None or len(interest_levels)==0):\n",
    "                    verbose_print(verbose,f\" * Skipping atmospheric variables as no interest levels have been requested\")\n",
    "                    continue # we do not care about atmospheric variables if no levels are of interest\n",
    "                \n",
    "                # select interest variables and levels\n",
    "                vars_interest_variables = [var for var in vars_ds.data_vars if var in interest_variables]\n",
    "                if var_type == \"atmospheric_ds\":\n",
    "                    vars_ds = vars_ds[vars_interest_variables].sel(level=interest_levels)\n",
    "                else:\n",
    "                    vars_ds = vars_ds[vars_interest_variables]\n",
    "                    \n",
    "                # override time coordinates using the era5_base_frequency\n",
    "                vars_ds = vars_ds.assign_coords(\n",
    "                    {\"time\": pd.date_range(init_time+warmup_steps*pd.Timedelta(era5_base_frequency), \n",
    "                                           periods=vars_ds.sizes[\"time\"], \n",
    "                                           freq=era5_base_frequency)})\n",
    "                \n",
    "                # aggregate at eval_agg frequency\n",
    "                # use pd.Timedelta to avoid xarray automatically starting the resampling \n",
    "                # on Mondays for weekly etc.\n",
    "                # Note that resulting'time' will be the first timestamp in the aggregated period\n",
    "                vars_ds = vars_ds.resample(time=pd.Timedelta(eval_aggregation), origin=init_time).mean()\n",
    "                vars_ds = vars_ds.rename({\"time\": \"lead_time\"})\n",
    "                vars_ds[\"lead_time\"] = vars_ds[\"lead_time\"] - np.datetime64(init_time)\n",
    "                \n",
    "                # per-variable processing\n",
    "                for var in vars_ds.data_vars:\n",
    "                    # add lead time\n",
    "                    var_ds = vars_ds[var]\n",
    "                    \n",
    "                    # save\n",
    "                    path = f\"forecast_{var}_\" + \"-\".join([\n",
    "                        init_time.strftime(\"%Y%m%dT%H%M%S\"),\n",
    "                        str(era5_base_frequency),\n",
    "                        str(eval_aggregation),\n",
    "                        str(eval_start),\n",
    "                        str(forecast_horizon),\n",
    "                        str(var_ds.sizes[\"longitude\"])+ \"x\" +str(var_ds.sizes[\"latitude\"]),\n",
    "                    ]) + \".nc\"\n",
    "                    path = os.path.join(output_dir, path)\n",
    "                    verbose_print(verbose, f\"   * Saving new {var_type} forecast: {path}\")\n",
    "                    xr_to_netcdf(\n",
    "                        var_ds, path, \n",
    "                        precision=\"float32\", \n",
    "                        compression_level=1, \n",
    "                        sort_time=False, \n",
    "                        exist_ok=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m AuroraBatchDataParallel(model)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#out = model.forward(batch)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "aurora_model = \"aurora-0.25-pretrained.ckpt\"\n",
    "model = ParallelAurora(use_lora=False)\n",
    "model.load_checkpoint(\"microsoft/aurora\", aurora_model)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = AuroraBatchDataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "out = model.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(aurora.batch.Batch,\n",
       " dict,\n",
       " torch.Size([4, 1, 180, 360]),\n",
       " torch.Size([180, 360]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out), type(out.surf_vars), out.surf_vars[\"2t\"].shape, out.static_vars[\"z\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.metadata.rollout_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2, 180, 360]), 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surf_vars[\"2t\"][0].shape, len(surf_vars[\"2t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from datetime import timedelta\n",
    "\n",
    "class ParallelAurora(Aurora):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, batch: Batch) -> Batch:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            batch (:class:`Batch`): Batch to run the model on.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no metric is provided.\n",
    "\n",
    "        Returns:\n",
    "            :class:`Batch`: Prediction for the batch.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure everything is on the same device and in the right format.\n",
    "        device = next(iter(batch.surf_vars.values())).device\n",
    "        batch = batch.type(torch.float32)\n",
    "        batch = batch.normalise()\n",
    "        batch = batch.crop(patch_size=self.patch_size)\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        H, W = batch.spatial_shape\n",
    "        patch_res = (\n",
    "            self.encoder.latent_levels,\n",
    "            H // self.encoder.patch_size,\n",
    "            W // self.encoder.patch_size,\n",
    "        )\n",
    "\n",
    "        # Insert batch and history dimension for static variables.\n",
    "        B, T = next(iter(batch.surf_vars.values())).shape[:2]\n",
    "        batch = dataclasses.replace(\n",
    "            batch,\n",
    "            static_vars={k: v[None, None].repeat(B, T, 1, 1) for k, v in batch.static_vars.items()},\n",
    "        )\n",
    "\n",
    "        x = self.encoder(\n",
    "            batch,\n",
    "            lead_time=timedelta(hours=6),\n",
    "        )\n",
    "        x = self.backbone(\n",
    "            x,\n",
    "            lead_time=timedelta(hours=6),\n",
    "            patch_res=patch_res,\n",
    "            rollout_step=batch.metadata.rollout_step,\n",
    "        )\n",
    "        pred = self.decoder(\n",
    "            x,\n",
    "            batch,\n",
    "            lead_time=timedelta(hours=6),\n",
    "            patch_res=patch_res,\n",
    "        )\n",
    "\n",
    "        # Remove batch and history dimension from static variables.\n",
    "        B, T = next(iter(batch.surf_vars.values()))[0]\n",
    "        pred = dataclasses.replace(\n",
    "            pred,\n",
    "            static_vars={k: v[0, 0] for k, v in batch.static_vars.items()},\n",
    "        )\n",
    "\n",
    "        # Insert history dimension in prediction. The time should already be right.\n",
    "        pred = dataclasses.replace(\n",
    "            pred,\n",
    "            surf_vars={k: v[:, None] for k, v in pred.surf_vars.items()},\n",
    "            atmos_vars={k: v[:, None] for k, v in pred.atmos_vars.items()},\n",
    "        )\n",
    "\n",
    "        pred = pred.unnormalise()\n",
    "\n",
    "        return pred\n",
    "    \n",
    "ParallelAuroraSmall = partial(\n",
    "    ParallelAurora,\n",
    "    encoder_depths=(2, 6, 2),\n",
    "    encoder_num_heads=(4, 8, 16),\n",
    "    decoder_depths=(2, 6, 2),\n",
    "    decoder_num_heads=(16, 8, 4),\n",
    "    embed_dim=256,\n",
    "    num_heads=8,\n",
    "    use_lora=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1699939/3131655674.py\", line 52, in forward\n    pred = self.decoder(\n           ^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/aurora/model/decoder.py\", line 162, in forward\n    x_atmos = self.deaggregate_levels(levels_embed, x[..., 1:, :])  # (B, L, C_A, D)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/aurora/model/decoder.py\", line 104, in deaggregate_levels\n    x = self.level_decoder(level_embed, x)  # (BxL, C, D)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/aurora/model/perceiver.py\", line 213, in forward\n    latents = attn_out + latents if self.residual_latent else attn_out\n              ~~~~~~~~~^~~~~~~~~\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.61 GiB. GPU \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AuroraBatchDataParallel(model)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:108\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    106\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 108\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1699939/3131655674.py\", line 52, in forward\n    pred = self.decoder(\n           ^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/aurora/model/decoder.py\", line 162, in forward\n    x_atmos = self.deaggregate_levels(levels_embed, x[..., 1:, :])  # (B, L, C_A, D)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/aurora/model/decoder.py\", line 104, in deaggregate_levels\n    x = self.level_decoder(level_embed, x)  # (BxL, C, D)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ewalt/.local/lib/python3.11/site-packages/aurora/model/perceiver.py\", line 213, in forward\n    latents = attn_out + latents if self.residual_latent else attn_out\n              ~~~~~~~~~^~~~~~~~~\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.61 GiB. GPU \n"
     ]
    }
   ],
   "source": [
    "model = ParallelAuroraSmall()#use_lora=False)\n",
    "model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-small-pretrained.ckpt\")#)\n",
    "model = AuroraBatchDataParallel(model)\n",
    "model = model.to(\"cuda\")\n",
    "model.forward(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
